#!/usr/bin/env python
# coding: utf-8

# In[4]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import os
import warnings
warnings.filterwarnings('ignore')

# GÃ¶rseller iÃ§in klasÃ¶r oluÅŸtur
output_dir = "kumeleme_sonuclari"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"'{output_dir}' klasÃ¶rÃ¼ oluÅŸturuldu")

# In[5]:


data = pd.read_csv('dava.csv')
print("Veri setinin orijinal sÃ¼tun isimleri:")
print(data.columns.tolist())

# Index sÃ¼tununu kaldÄ±r
data_clean = data.drop('Unnamed: 0', axis=1)

# SÃ¼tun isimlerini basitleÅŸtir
data_clean.columns = ['Case_Duration', 'Witnesses', 'Legal_Fees', 'Evidence_Items', 'Severity', 'Outcome']

print(f"\nDÃ¼zeltilmiÅŸ veri boyutu: {data_clean.shape}")
print(data_clean.head())

# ## GÃ–REV 1: Ã–zellik SeÃ§imi
features = ['Case_Duration', 'Witnesses', 'Legal_Fees', 'Evidence_Items', 'Severity']
X = data_clean[features]

# Ã–zellikleri standardize etme
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(f"\nÃ–zelliklerin boyutu: {X_scaled.shape}")

# ## GÃ–REV 2: Optimal KÃ¼me SayÄ±sÄ±nÄ± Belirleme

# Elbow yÃ¶ntemi ile optimal kÃ¼me sayÄ±sÄ±
inertia = []
k_range = range(1, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Elbow grafiÄŸi
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia, 'bo-', markersize=8, linewidth=2)
plt.xlabel('KÃ¼me SayÄ±sÄ± (k)')
plt.ylabel('Inertia (Within-cluster sum of squares)')
plt.title('Elbow YÃ¶ntemi - Optimal KÃ¼me SayÄ±sÄ±')
plt.grid(True, alpha=0.3)
plt.savefig(f'{output_dir}/elbow_method.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/elbow_method.pdf', bbox_inches='tight')
plt.show()

# Silhouette skorlarÄ±
silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_scaled)
    silhouette_avg = silhouette_score(X_scaled, cluster_labels)
    silhouette_scores.append(silhouette_avg)

# Daha iyi yorumlanabilirlik iÃ§in 3 kÃ¼me seÃ§elim
optimal_k = 3

print(f"\nSeÃ§ilen optimal kÃ¼me sayÄ±sÄ±: {optimal_k}")

# ## GÃ–REV 3: K-Means ile KÃ¼meleme

print(f"\nK-Means kÃ¼meleme iÅŸlemi (k={optimal_k})...")
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(X_scaled)

data_clean['Cluster'] = cluster_labels

print("\nKÃ¼me DaÄŸÄ±lÄ±mÄ±:")
cluster_distribution = data_clean['Cluster'].value_counts().sort_index()
print(cluster_distribution)

print("\nKÃ¼me Ã–zellikleri (Ortalamalar):")
cluster_summary = data_clean.groupby('Cluster')[features + ['Outcome']].mean()
print(cluster_summary.round(2))

# ## GÃ–REV 4: GÃ¶rselleÅŸtirme ve Yorumlama

print("\nGeliÅŸmiÅŸ GÃ¶rselleÅŸtirme...")

# 1. ANA GÃ–RSELLEÅTÄ°RME PANELÄ°
plt.figure(figsize=(20, 15))

# 1.1 Ana Ã–zelliklerin DaÄŸÄ±lÄ±mÄ±
plt.subplot(3, 3, 1)
scatter = plt.scatter(data_clean['Legal_Fees'], data_clean['Case_Duration'], 
                     c=data_clean['Cluster'], cmap='Set2', alpha=0.8, s=80, edgecolors='black')
plt.xlabel('Hukuk Maliyetleri (USD)')
plt.ylabel('Dava SÃ¼resi (GÃ¼n)')
plt.title('KÃ¼meler: Maliyet vs SÃ¼re')
plt.colorbar(scatter, label='KÃ¼me')
plt.grid(True, alpha=0.3)

# 1.2 TanÄ±k ve Delil DaÄŸÄ±lÄ±mÄ±
plt.subplot(3, 3, 2)
scatter = plt.scatter(data_clean['Witnesses'], data_clean['Evidence_Items'], 
                     c=data_clean['Cluster'], cmap='Set2', alpha=0.8, s=80, edgecolors='black')
plt.xlabel('TanÄ±k SayÄ±sÄ±')
plt.ylabel('Delil SayÄ±sÄ±')
plt.title('KÃ¼meler: TanÄ±k vs Delil')
plt.colorbar(scatter, label='KÃ¼me')
plt.grid(True, alpha=0.3)

# 1.3 KÃ¼me BÃ¼yÃ¼klÃ¼kleri
plt.subplot(3, 3, 3)
cluster_counts = data_clean['Cluster'].value_counts().sort_index()
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
plt.pie(cluster_counts.values, labels=[f'KÃ¼me {i}' for i in cluster_counts.index], 
        autopct='%1.1f%%', colors=colors, startangle=90)
plt.title('KÃ¼melere GÃ¶re Dava DaÄŸÄ±lÄ±mÄ±')

# 1.4 Ciddiyet DaÄŸÄ±lÄ±mÄ±
plt.subplot(3, 3, 4)
severity_by_cluster = pd.crosstab(data_clean['Cluster'], data_clean['Severity'])
severity_by_cluster.plot(kind='bar', ax=plt.gca(), color=['#FF9999', '#66B2FF', '#99FF99'])
plt.xlabel('KÃ¼me')
plt.ylabel('Dava SayÄ±sÄ±')
plt.title('KÃ¼melere GÃ¶re Ciddiyet DÃ¼zeyi')
plt.legend(title='Ciddiyet', labels=['DÃ¼ÅŸÃ¼k', 'Orta', 'YÃ¼ksek'])
plt.xticks(rotation=0)

# 1.5 Outcome DaÄŸÄ±lÄ±mÄ±
plt.subplot(3, 3, 5)
outcome_by_cluster = pd.crosstab(data_clean['Cluster'], data_clean['Outcome'])
outcome_by_cluster.plot(kind='bar', ax=plt.gca(), color=['#FF6B6B', '#4ECDC4'])
plt.xlabel('KÃ¼me')
plt.ylabel('Dava SayÄ±sÄ±')
plt.title('KÃ¼melere GÃ¶re SonuÃ§ DaÄŸÄ±lÄ±mÄ±')
plt.legend(title='SonuÃ§', labels=['Aleyhte', 'Lehte'])
plt.xticks(rotation=0)

# 1.6 Ã–zellik OrtalamalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±
plt.subplot(3, 3, 6)
cluster_means = data_clean.groupby('Cluster')[['Legal_Fees', 'Case_Duration']].mean()
cluster_means.plot(kind='bar', ax=plt.gca(), color=['#FF6B6B', '#4ECDC4'])
plt.xlabel('KÃ¼me')
plt.ylabel('Ortalama DeÄŸer')
plt.title('KÃ¼melere GÃ¶re Maliyet ve SÃ¼re OrtalamalarÄ±')
plt.legend(title='Ã–zellik', labels=['Maliyet (USD)', 'SÃ¼re (GÃ¼n)'])
plt.xticks(rotation=0)

# 1.7 Witnesses vs Legal Fees
plt.subplot(3, 3, 7)
scatter = plt.scatter(data_clean['Witnesses'], data_clean['Legal_Fees'], 
                     c=data_clean['Cluster'], cmap='Set2', alpha=0.8, s=80, edgecolors='black')
plt.xlabel('TanÄ±k SayÄ±sÄ±')
plt.ylabel('Hukuk Maliyetleri (USD)')
plt.title('KÃ¼meler: TanÄ±k vs Maliyet')
plt.colorbar(scatter, label='KÃ¼me')
plt.grid(True, alpha=0.3)

# 1.8 Evidence vs Duration
plt.subplot(3, 3, 8)
scatter = plt.scatter(data_clean['Evidence_Items'], data_clean['Case_Duration'], 
                     c=data_clean['Cluster'], cmap='Set2', alpha=0.8, s=80, edgecolors='black')
plt.xlabel('Delil SayÄ±sÄ±')
plt.ylabel('Dava SÃ¼resi (GÃ¼n)')
plt.title('KÃ¼meler: Delil vs SÃ¼re')
plt.colorbar(scatter, label='KÃ¼me')
plt.grid(True, alpha=0.3)

# 1.9 KÃ¼me Ã–zellik KarÅŸÄ±laÅŸtÄ±rmasÄ±
plt.subplot(3, 3, 9)
cluster_features = data_clean.groupby('Cluster')[['Witnesses', 'Evidence_Items', 'Severity']].mean()
cluster_features.plot(kind='bar', ax=plt.gca(), color=['#FF9999', '#66B2FF', '#99FF99'])
plt.xlabel('KÃ¼me')
plt.ylabel('Ortalama DeÄŸer')
plt.title('DiÄŸer Ã–zellik OrtalamalarÄ±')
plt.legend(title='Ã–zellik', labels=['TanÄ±k', 'Delil', 'Ciddiyet'])
plt.xticks(rotation=0)

plt.tight_layout()
plt.savefig(f'{output_dir}/ana_kumeleme_paneli.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/ana_kumeleme_paneli.pdf', bbox_inches='tight')
plt.show()

# 2. KORELASYON MATRÄ°SÄ°
plt.figure(figsize=(12, 10))
correlation_matrix = data_clean[features + ['Outcome', 'Cluster']].corr()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, fmt='.2f', cbar_kws={'shrink': 0.8},
            mask=mask)
plt.title('Ã–zellikler ve KÃ¼meler ArasÄ± Korelasyon Matrisi', fontsize=14, pad=20)
plt.tight_layout()
plt.savefig(f'{output_dir}/korelasyon_matrisi.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/korelasyon_matrisi.pdf', bbox_inches='tight')
plt.show()

# 3. PAIRPLOT GÃ–RSELLEÅTÄ°RMESÄ°
plt.figure(figsize=(16, 12))
pairplot = sns.pairplot(data_clean, vars=features, hue='Cluster', 
                        palette='Set2', diag_kind='hist', 
                        plot_kws={'alpha': 0.7, 's': 60, 'edgecolor': 'black'})
pairplot.fig.suptitle('Ã–zelliklerin KÃ¼melere GÃ¶re DaÄŸÄ±lÄ±mÄ±', y=1.02, fontsize=16)
plt.savefig(f'{output_dir}/pairplot_kumeleme.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/pairplot_kumeleme.pdf', bbox_inches='tight')
plt.show()

# 4. RADAR CHART GÃ–RSELLEÅTÄ°RMESÄ°
from math import pi

def normalize_features(df, features):
    normalized = df[features].copy()
    for feature in features:
        normalized[feature] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())
    return normalized

# Radar chart iÃ§in veri hazÄ±rla
cluster_means_normalized = data_clean.groupby('Cluster')[features].mean()
cluster_means_normalized = normalize_features(cluster_means_normalized, features)

# Radar chart
fig = plt.figure(figsize=(18, 6))
categories = ['Dava SÃ¼resi', 'TanÄ±k SayÄ±sÄ±', 'Hukuk Maliyetleri', 'Delil SayÄ±sÄ±', 'Ciddiyet DÃ¼zeyi']
N = len(categories)

for cluster in range(optimal_k):
    values = cluster_means_normalized.loc[cluster].values.tolist()
    values += values[:1]  # Ã‡emberi tamamlamak iÃ§in
    
    angles = [n / float(N) * 2 * pi for n in range(N)]
    angles += angles[:1]
    
    ax = plt.subplot(1, optimal_k, cluster+1, polar=True)
    plt.xticks(angles[:-1], categories, color='grey', size=10)
    ax.plot(angles, values, linewidth=3, linestyle='solid', label=f'KÃ¼me {cluster}', 
            color=colors[cluster])
    ax.fill(angles, values, alpha=0.25, color=colors[cluster])
    plt.title(f'KÃ¼me {cluster} Profili', size=14, color='navy', y=1.1)
    plt.ylim(0, 1)

plt.tight_layout()
plt.savefig(f'{output_dir}/radar_chart_kume_profilleri.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/radar_chart_kume_profilleri.pdf', bbox_inches='tight')
plt.show()

# 5. KÃœME BAÅARI ORANLARI GRAFÄ°ÄÄ°
plt.figure(figsize=(10, 6))
outcome_percentage = pd.crosstab(data_clean['Cluster'], data_clean['Outcome'], normalize='index') * 100
outcome_percentage.plot(kind='bar', stacked=True, color=['#FF6B6B', '#4ECDC4'], ax=plt.gca())
plt.xlabel('KÃ¼me')
plt.ylabel('YÃ¼zde (%)')
plt.title('KÃ¼melere GÃ¶re Lehte/Aleyhte SonuÃ§ DaÄŸÄ±lÄ±mÄ±')
plt.legend(title='SonuÃ§', labels=['Aleyhte', 'Lehte'])
plt.xticks(rotation=0)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig(f'{output_dir}/kume_basari_oranlari.png', dpi=300, bbox_inches='tight')
plt.savefig(f'{output_dir}/kume_basari_oranlari.pdf', bbox_inches='tight')
plt.show()

# 6. 3D GÃ–RSELLEÅTÄ°RME
try:
    from mpl_toolkits.mplot3d import Axes3D
    fig = plt.figure(figsize=(15, 10))
    
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(data_clean['Legal_Fees'], 
                        data_clean['Case_Duration'], 
                        data_clean['Witnesses'],
                        c=data_clean['Cluster'], 
                        cmap='Set2', 
                        s=80, 
                        alpha=0.8,
                        edgecolors='black')
    
    ax.set_xlabel('Hukuk Maliyetleri (USD)')
    ax.set_ylabel('Dava SÃ¼resi (GÃ¼n)')
    ax.set_zlabel('TanÄ±k SayÄ±sÄ±')
    ax.set_title('3D KÃ¼meleme GÃ¶rselleÅŸtirmesi\n(Maliyet vs SÃ¼re vs TanÄ±k)')
    plt.colorbar(scatter, label='KÃ¼me')
    plt.savefig(f'{output_dir}/3d_kumeleme.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_dir}/3d_kumeleme.pdf', bbox_inches='tight')
    plt.show()
except ImportError:
    print("3D gÃ¶rselleÅŸtirme iÃ§in mpl_toolkits gerekli")

# ## DETAYLI KÃœME PROFÄ°L ANALÄ°ZÄ°
print("\n" + "="*70)
print("DETAYLI KÃœME PROFÄ°L ANALÄ°ZÄ°")
print("="*70)

for cluster in range(optimal_k):
    cluster_data = data_clean[data_clean['Cluster'] == cluster]
    print(f"\nğŸ” --- KÃœME {cluster} PROFÄ°LÄ° ---")
    print(f"   Dava SayÄ±sÄ±: {len(cluster_data)} ({len(cluster_data)/len(data_clean)*100:.1f}%)")
    print(f"   ğŸ“… Ortalama Dava SÃ¼resi: {cluster_data['Case_Duration'].mean():.1f} gÃ¼n")
    print(f"   ğŸ‘¥ Ortalama TanÄ±k SayÄ±sÄ±: {cluster_data['Witnesses'].mean():.1f}")
    print(f"   ğŸ’° Ortalama Hukuk Maliyeti: ${cluster_data['Legal_Fees'].mean():.2f}")
    print(f"   ğŸ“‹ Ortalama Delil SayÄ±sÄ±: {cluster_data['Evidence_Items'].mean():.1f}")
    print(f"   âš–ï¸  Ortalama Ciddiyet: {cluster_data['Severity'].mean():.2f}")
    print(f"   âœ… Lehte SonuÃ§ OranÄ±: {cluster_data['Outcome'].mean():.2%}")

# ## SONUÃ‡LARI CSV OLARAK KAYDET
data_clean.to_csv(f'{output_dir}/kumeleme_sonuclari.csv', index=False)
cluster_summary.to_csv(f'{output_dir}/kume_ozet_istatistikleri.csv')

print(f"\nğŸ“ SONUÃ‡LAR KAYDEDÄ°LDÄ°:")
print(f"   âœ… GÃ¶rseller: '{output_dir}' klasÃ¶rÃ¼ne kaydedildi")
print(f"   âœ… Veriler: '{output_dir}/kumeleme_sonuclari.csv'")
print(f"   âœ… Ä°statistikler: '{output_dir}/kume_ozet_istatistikleri.csv'")

# ## FÄ°NAL RAPOR
print("\n" + "="*80)
print("KÃœMELEME ANALÄ°ZÄ° RAPORU")
print("="*80)

print(f"""
ğŸ“Š ANALÄ°Z Ã–ZETÄ°:

â€¢ Toplam Dava SayÄ±sÄ±: {len(data_clean)}
â€¢ KullanÄ±lan Ã–zellikler: {len(features)}
â€¢ Optimal KÃ¼me SayÄ±sÄ±: {optimal_k}
â€¢ Silhouette Skoru: {silhouette_score(X_scaled, cluster_labels):.4f}

ğŸ¯ KÃœME PROFÄ°LLERÄ°:

{cluster_summary.round(2)}

ğŸ’¡ Ä°Å Ä°Ã‡GÃ–RÃœLERÄ°:

1. KAYNAK OPTÄ°MÄ°ZASYONU: YÃ¼ksek maliyetli kÃ¼meler iÃ§in Ã¶zel kaynak ayÄ±rÄ±n
2. RÄ°SK YÃ–NETÄ°MÄ°: Uzun sÃ¼reli ve yÃ¼ksek maliyetli davalarÄ± yakÄ±ndan takip edin  
3. SÃœREÃ‡ Ä°YÄ°LEÅTÄ°RME: Benzer profildeki davalar iÃ§in standart sÃ¼reÃ§ler geliÅŸtirin
4. BAÅARI ANALÄ°ZÄ°: Lehte sonuÃ§ oranlarÄ±nÄ± kÃ¼meler bazÄ±nda deÄŸerlendirin

ğŸ“ˆ GÃ–RSELLER:
â€¢ {output_dir}/ana_kumeleme_paneli.png - Ana analiz paneli
â€¢ {output_dir}/korelasyon_matrisi.png - Korelasyon analizi
â€¢ {output_dir}/pairplot_kumeleme.png - DetaylÄ± daÄŸÄ±lÄ±m analizi
â€¢ {output_dir}/radar_chart_kume_profilleri.png - KÃ¼me profilleri
â€¢ {output_dir}/kume_basari_oranlari.png - BaÅŸarÄ± oranlarÄ±

âœ… ANALÄ°Z TAMAMLANDI!
""")